# -*- coding: utf-8 -*-
# @Time    : 2024/5/20 5:20
# @Author  : XianYangğŸš€
# @Email   : xy_mts@163.com
# @File    : models.py
# ------â¤â¤â¤------ #

import logging
import os
import time
from collections import Counter
from scipy.spatial import Delaunay
from scipy.spatial.distance import cdist

import colorlog
import cupy as cp
import cv2
import numpy as np
import onnxruntime as ort
import tensorrt as trt
from cuda import cudart

os.environ['CUDA_MODULE_LOADING'] = 'LAZY'


class My_detection():
    def __init__(self):
        self.Models = None
        self.conf_threshold = 0.45
        self.iou_threshold = 0.45
        self.classes = None
        self.color_palette = None
        self.logger = My_LoggerConfig().get_logger()

    def __call__(self, image):
        pre_start_time = time.time()
        im, ratio, pad_w, pad_h = self.preprocess(image, self.Models.input_shapes[0][2:])
        pre_end_time = time.time()
        # æ¨ç†
        inf_start_time = time.time()
        pred = self.Models(im)
        inf_end_time = time.time()
        # åå¤„ç†
        post_start_time = time.time()
        results = self.postprocess(pred, im, image, ratio, pad_w, pad_h, self.conf_threshold, self.iou_threshold)
        post_end_time = time.time()
        # ç»Ÿè®¡æ¨ç†æ—¶é—´ç”¨äºæ‰“å°
        self.message = [(pre_end_time - pre_start_time) * 1000, (inf_end_time - inf_start_time) * 1000,
                        (post_end_time - post_start_time) * 1000]
        return results

    def warm_up(self, n):
        """æ¨¡å‹é¢„çƒ­"""
        size = self.Models.input_shapes[0][2:]
        for i in range(n):
            dummy_input = np.random.rand(1, 3, *size).astype(self.Models.dtypes)
            self.Models(dummy_input)
        print("Model Warmup " + f"{n}" + " times")

    def preprocess(self, image, img_size):
        """é¢„å¤„ç†"""
        img, ratio, (dw, dh) = self.letterbox(image, img_size, stride=32, auto=False)
        # ä½¿ç”¨ CuPy è¿›è¡Œå›¾åƒå¤„ç†
        img_cp = cp.asarray(img)  # å°† NumPy æ•°ç»„è½¬æ¢ä¸º CuPy æ•°ç»„
        img_cp = img_cp[:, :, ::-1].transpose(2, 0, 1)  # è½¬æ¢è‰²å½©ç©ºé—´å¹¶è½¬ç½®ç»´åº¦
        img_cp = cp.ascontiguousarray(img_cp)  # è½¬æ¢ä¸ºè¿ç»­æ•°ç»„
        img_cp = img_cp.astype(cp.float16 if self.Models.dtypes == np.float16 else cp.float32)  # ä½¿ç”¨ CuPy è¿›è¡Œç±»å‹è½¬æ¢
        img_cp /= 255.0  # æ ‡å‡†åŒ–åƒç´ å€¼
        img = cp.asnumpy(img_cp)  # å°† CuPy æ•°ç»„è½¬æ¢å› NumPy æ•°ç»„
        return img[None], ratio, dw, dh  # è¿”å›é¢„å¤„ç†åçš„å›¾åƒå’Œç›¸å…³å‚æ•°

    def letterbox(self, im, new_shape, color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):
        """ç­‰æ¯”ä¾‹ç¼©æ”¾ """
        shape = im.shape[:2]  # current shape [height, width]
        if isinstance(new_shape, int):
            new_shape = (new_shape, new_shape)

        # Scale ratio (new / old)
        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
        if not scaleup:  # only scale down, do not scale up (for better val mAP)
            r = min(r, 1.0)

        # Compute padding
        ratio = r, r  # width, height ratios
        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
        dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding
        if auto:  # minimum rectangle
            dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding
        elif scaleFill:  # stretch
            dw, dh = 0.0, 0.0
            new_unpad = (new_shape[1], new_shape[0])
            ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios

        dw /= 2  # divide padding into 2 sides
        dh /= 2

        if shape[::-1] != new_unpad:  # resize
            im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)
        top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
        left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
        im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border
        return im, ratio, (dw, dh)

    def non_max_suppression(self, prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False,
                            multi_label=False, labels=(), max_det=300, nc=0, max_time_img=0.05, max_nms=30000,
                            max_wh=7680, ):
        """ nms"""
        assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'
        assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'
        if isinstance(prediction,
                      (list, tuple)):  # YOLOv8 model in validation model, output = (inference_out, loss_out)
            prediction = prediction[0]  # select only inference output

        bs = prediction.shape[0]  # batch size
        nc = nc or (prediction.shape[1] - 4)  # number of classes
        nm = prediction.shape[1] - nc - 4
        mi = 4 + nc  # mask start index
        xc = prediction[:, 4:mi].max(1) > conf_thres  # candidates
        # Settings
        # min_wh = 2  # (pixels) minimum box width and height
        time_limit = 0.5 + max_time_img * bs  # seconds to quit after
        redundant = True  # require redundant detections
        multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)
        merge = False  # use merge-NMS

        output = [np.zeros((0, 6 + nm))] * bs
        for xi, x in enumerate(prediction):  # image index, image inference
            # Apply constraints
            # x[((x[:, 2:4] < min_wh) | (x[:, 2:4] > max_wh)).any(1), 4] = 0  # width-height
            x = x.transpose(1, 0)[xc[xi]]  # confidence

            # Cat apriori labels if autolabelling
            if labels and len(labels[xi]):
                lb = labels[xi]
                v = np.zeros((len(lb), nc + nm + 5))
                v[:, :4] = lb[:, 1:5]  # box
                v[range(len(lb)), lb[:, 0].long() + 4] = 1.0  # cls
                x = np.concatenate((x, v), 0)

            # If none remain process next image
            if not x.shape[0]:
                continue

            # Detections matrix nx6 (xyxy, conf, cls) ndarrayä¸å¥½ç›´æ¥split
            # box, cls, mask = np.split(x,[4, nc, nm], 1)
            box = self.xywh2xyxy(x[:, :4])
            cls = x[:, 4:mi]
            mask = x[:, mi:]

            if multi_label:
                i, j = (cls > conf_thres).nonzero(as_tuple=False).T
                x = np.concatenate((box[i], x[i, 4 + j, None], j[:, None].float(), mask[i]), 1)
            else:  # best class only
                conf = np.max(x[:, 4:mi], 1).reshape(box.shape[:1][0], 1)
                j = np.argmax(x[:, 4:mi], 1).reshape(box.shape[:1][0], 1)
                x = np.concatenate((box, conf, j, mask), 1)[conf.reshape(box.shape[:1][0]) > conf_thres]

            # Filter by class
            if classes is not None:
                x = x[(x[:, 5:6] == np.array(classes, device=x.device)).any(1)]

            # Check shape
            n = x.shape[0]  # number of boxes
            if not n:  # no boxes
                continue
            x = x[x[:, 4].argsort(axis=0)[:max_nms]]  # sort by confidence and remove excess boxes

            # Batched NMS
            c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes
            boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores
            i = self.nms_boxes(boxes, scores)  # NMS
            i = i[:max_det]  # limit detections
            if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)
                # Update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)
                iou = self.box_iou(boxes[i], boxes) > iou_thres  # iou matrix
                weights = iou * scores[None]  # box weights
                x[i, :4] = np.multiply(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes
                if redundant:
                    i = i[iou.sum(1) > 1]  # require redundancy

            output[xi] = x[i]

        return output

    def xywh2xyxy(self, x):
        """ä¸­å¿ƒç‚¹è½¬æ¢"""
        y = np.copy(x)
        y[..., 0] = x[..., 0] - x[..., 2] / 2  # top left x
        y[..., 1] = x[..., 1] - x[..., 3] / 2  # top left y
        y[..., 2] = x[..., 0] + x[..., 2] / 2  # bottom right x
        y[..., 3] = x[..., 1] + x[..., 3] / 2  # bottom right y
        return y

    def nms_boxes(self, boxes, scores):
        """NMS0"""
        x = boxes[:, 0]
        y = boxes[:, 1]
        w = boxes[:, 2] - boxes[:, 0]
        h = boxes[:, 3] - boxes[:, 1]
        areas = w * h
        order = scores.argsort()[::-1]
        keep = []
        while order.size > 0:
            i = order[0]
            keep.append(i)
            xx1 = np.maximum(x[i], x[order[1:]])
            yy1 = np.maximum(y[i], y[order[1:]])
            xx2 = np.minimum(x[i] + w[i], x[order[1:]] + w[order[1:]])
            yy2 = np.minimum(y[i] + h[i], y[order[1:]] + h[order[1:]])
            w1 = np.maximum(0.0, xx2 - xx1 + 0.00001)
            h1 = np.maximum(0.0, yy2 - yy1 + 0.00001)
            inter = w1 * h1
            ovr = inter / (areas[i] + areas[order[1:]] - inter)
            inds = np.where(ovr <= 0.45)[0]
            order = order[inds + 1]
        keep = np.array(keep)
        return keep

    def box_iou(self, box1, box2, eps=1e-7):
        (a1, a2), (b1, b2) = box1.unsqueeze(1).chunk(2, 2), box2.unsqueeze(0).chunk(2, 2)
        inter = (np.min(a2, b2) - np.max(a1, b1)).clamp(0).prod(2)
        return inter / ((a2 - a1).prod(2) + (b2 - b1).prod(2) - inter + eps)

    def postprocess(self, pred, im0, image, ratio, pad_w, pad_h, conf_threshold, iou_threshold, nm=32):
        pass

    def scale_mask(self, masks, im0_shape, ratio_pad=None):
        im1_shape = masks.shape[:2]
        if ratio_pad is None:  # calculate from im0_shape
            gain = min(im1_shape[0] / im0_shape[0], im1_shape[1] / im0_shape[1])  # gain = old / new
            pad = (im1_shape[1] - im0_shape[1] * gain) / 2, (im1_shape[0] - im0_shape[0] * gain) / 2  # wh padding
        else:
            pad = ratio_pad[1]
        # Calculate tlbr of mask
        top, left = int(round(pad[1] - 0.1)), int(round(pad[0] - 0.1))  # y, x
        bottom, right = int(round(im1_shape[0] - pad[1] + 0.1)), int(round(im1_shape[1] - pad[0] + 0.1))
        if len(masks.shape) < 2:
            raise ValueError(f'"len of masks shape" should be 2 or 3, but got {len(masks.shape)}')
        # Slicing and resizing
        masks = masks[top:bottom, left:right]
        masks = cp.asnumpy(masks)  # Convert to numpy for OpenCV
        masks = cv2.resize(masks, (im0_shape[1], im0_shape[0]),
                           interpolation=cv2.INTER_LINEAR)  # INTER_CUBIC would be better
        # Ensure masks has third dimension
        if len(masks.shape) == 2:
            masks = masks[:, :, None]

        return cp.asarray(masks)  # Convert back to CuPy array

    def my_show0(self, seg, im):
        s = 'Result: '
        if len(seg[0]) != 0:
            bboxes, segments = seg[0], seg[1]
            for count, element in [(j, self.classes[i]) for i, j in
                                   Counter([int(result[-1]) for result in bboxes[0]]).items()]:
                s += f"{element}*{count} "
            im_canvas = im.copy()
            for (*box, conf, cls_), segment in zip(bboxes[0], segments[0]):
                if int(cls_) in self.lane_seg_other:  # seg --->label in self.seg dict key ?
                    # è®¡ç®—æ–‡æœ¬çš„å¤§å°
                    text = f'{self.classes[cls_]}:{conf:.3f}'
                    (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
                    # è®¡ç®—çŸ©å½¢æ¡†å’Œæ–‡æœ¬ä½ç½®
                    top_left = (int(box[0] + (box[2] - box[0]) / 2) - 5, int(box[1] + (box[3] - box[1]) / 2) - 5)
                    bottom_right = (top_left[0] + text_width + 10, top_left[1] + text_height + 10)
                    # ç»˜åˆ¶çŸ©å½¢æ¡†å¹¶åœ¨æ¡†å†…ç»˜åˆ¶æ–‡æœ¬
                    cv2.rectangle(im, top_left, bottom_right, self.color_palette[int(cls_)], -1)
                    cv2.putText(im, text, (top_left[0] + (bottom_right[0] - top_left[0] - text_width) // 2,
                                           top_left[1] + (bottom_right[1] - top_left[1] + text_height) // 2),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)
                    cv2.fillPoly(im_canvas, np.int32([segment]), self.color_palette[int(cls_)])
                    # # cv2.polylines(im, np.int32([segment]), True, (255, 0, 255), 2)
                else:
                    self.drawYOLO(im, box, conf, cls_)

            im = cv2.addWeighted(im_canvas, 0.3, im, 0.7, 0)
        message = f"ğŸš€ğŸš€ğŸš€ Total:{(self.message[0] + self.message[1] + self.message[2]):6.2f}ms," \
                  f" Pre:{self.message[0]:6.2f}ms," \
                  f" Infer:{self.message[1]:6.2f}ms," \
                  f" Post:{self.message[2]:6.2f}ms - | \033[95m{s}\033[0m"
        self.logger.info(message)
        return im

    def my_show_track(self, seg, im):
        s = 'Result: '
        if len(seg[0]) != 0:
            bboxes, segments = seg[0], seg[1]
            for count, element in [(j, self.classes[i]) for i, j in
                                   Counter([int(result[-1]) for result in bboxes[0]]).items()]:
                s += f"{element}*{count} "
            im_canvas = im.copy()
            for (*box, conf, track_id, cls_), segment in zip(bboxes[0], segments[0]):
                if int(cls_) in self.lane_seg_other:
                    text = f'{self.classes[cls_]}:{conf:.3f} ID: {int(track_id)}'
                    (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
                    # è®¡ç®—çŸ©å½¢æ¡†å’Œæ–‡æœ¬ä½ç½®
                    top_left = (int(box[0] + (box[2] - box[0]) / 2) - 5, int(box[1] + (box[3] - box[1]) / 2) - 5)
                    bottom_right = (top_left[0] + text_width + 10, top_left[1] + text_height + 10)
                    # ç»˜åˆ¶çŸ©å½¢æ¡†å¹¶åœ¨æ¡†å†…ç»˜åˆ¶æ–‡æœ¬
                    cv2.rectangle(im, top_left, bottom_right, self.color_palette[int(cls_)], -1)
                    cv2.putText(im, text, (top_left[0] + (bottom_right[0] - top_left[0] - text_width) // 2,
                                           top_left[1] + (bottom_right[1] - top_left[1] + text_height) // 2),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)
                    if not int(cls_) in [i for i in range(len(self.lane))]:  # lane line types
                        cv2.fillPoly(im_canvas, np.int32([segment]), self.color_palette[int(cls_)])  # æ·»åŠ æ©ç æ•ˆæœ
                    # cv2.polylines(im, np.int32([segment]), True, (255, 0, 255), 2) # ç”»å‡ºè½®å»“çº¿
                else:
                    self.drawYOLO(im, box, conf, cls_, int(track_id))

            im = cv2.addWeighted(im_canvas, 0.3, im, 0.7, 0)
        message = f"ğŸš€ğŸš€ğŸš€ Total:{(self.message[0] + self.message[1] + self.message[2]):6.2f}ms," \
                  f" Pre:{self.message[0]:6.2f}ms," \
                  f" Infer:{self.message[1]:6.2f}ms," \
                  f" Post:{self.message[2]:6.2f}ms - | \033[95m{s}\033[0m"
        self.logger.info(message)

        return im

    # å¯è§†åŒ–ä¼˜åŒ–
    def my_show(self, seg, im, masks, show_track=False):
        s = 'Result: '
        if len(seg[0]) != 0:
            bboxes, segments = seg[0], seg[1]
            # ç»Ÿè®¡æ¯ç§ç±»åˆ«çš„æ•°é‡
            for count, element in [(j, self.classes[i]) for i, j in
                                   Counter([int(result[-1]) for result in bboxes[0]]).items()]:
                s += f"{element}*{count} "

            im_canvas = im.copy()
            for data in zip(bboxes[0], segments[0], masks):
                # å¤„ç† bbox å’Œ mask
                if show_track:
                    (*box, conf, track_id, cls_) = data[0]
                else:
                    (*box, conf, cls_) = data[0]
                segment, mask = data[1], data[2]

                # å¦‚æœç±»åˆ«å±äº lane_seg_otherï¼Œè¿›è¡Œè‡ªå®šä¹‰ç»˜åˆ¶
                if int(cls_) in self.lane_seg_other:
                    # è®¡ç®—è´¨å¿ƒ
                    moments = cv2.moments(mask.astype(np.uint8))  # è®¡ç®—è´¨å¿ƒ

                    if moments["m00"] != 0:
                        centroid_x = int(moments["m10"] / moments["m00"])
                        centroid_y = int(moments["m01"] / moments["m00"])
                    else:
                        centroid_x = int(box[0] + (box[2] - box[0]) / 2)
                        centroid_y = int(box[1] + (box[3] - box[1]) / 2)

                    # æ–‡æœ¬å†…å®¹
                    if show_track:
                        text = f'{self.classes[cls_]}:{conf:.3f} ID: {int(track_id)}'
                    else:
                        text = f'{self.classes[cls_]}:{conf:.3f}'

                    (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)

                    # çŸ©å½¢æ¡†ä½ç½®
                    top_left = (centroid_x - text_width // 2 - 5, centroid_y - text_height // 2 - 5)
                    bottom_right = (top_left[0] + text_width + 10, top_left[1] + text_height + 10)

                    # ç»˜åˆ¶çŸ©å½¢æ¡†å’Œæ–‡æœ¬
                    cv2.rectangle(im, top_left, bottom_right, self.color_palette[int(cls_)], -1)
                    cv2.putText(im, text, (top_left[0] + (bottom_right[0] - top_left[0] - text_width) // 2,
                                           top_left[1] + (bottom_right[1] - top_left[1] + text_height) // 2),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)

                    # ç»˜åˆ¶æ©ç 
                    if not int(cls_) in [i for i in range(len(self.lane))]:  # lane line types
                        cv2.fillPoly(im_canvas, np.int32([segment]), self.color_palette[int(cls_)])
                else:
                    if show_track:
                        self.drawYOLO(im, box, conf, cls_, int(track_id))
                    else:
                        self.drawYOLO(im, box, conf, cls_)

            # èåˆå›¾åƒ
            im = cv2.addWeighted(im_canvas, 0.3, im, 0.7, 0)

        # æ‰“å°ä¿¡æ¯
        message = f"ğŸš€ğŸš€ğŸš€ Total:{(self.message[0] + self.message[1] + self.message[2]):6.2f}ms," \
                  f" Pre:{self.message[0]:6.2f}ms," \
                  f" Infer:{self.message[1]:6.2f}ms," \
                  f" Post:{self.message[2]:6.2f}ms - | \033[95m{s}\033[0m"
        self.logger.info(message)

        return im

    def drawYOLO(self, im0, box, score, class_id, track_id=None):
        "ç”»yoloæ¡†"
        color = self.color_palette[int(class_id)]
        p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))
        cv2.rectangle(im0, p1, p2, color, 2)
        label = f'{self.classes[class_id]}: {score:.2f} ID: {int(track_id)}' if track_id else f'{self.classes[class_id]}: {score:.2f}'
        w0, h0 = cv2.getTextSize(label, 0, 0.5, 1)[0]
        outside = p1[1] - h0 >= 3
        p2 = p1[0] + w0, p1[1] - h0 - 3 if outside else p1[1] + h0 + 3
        cv2.rectangle(im0, p1, p2, color, -1, cv2.LINE_AA)
        cv2.putText(im0, label, (p1[0], p1[1] - 2 if outside else p1[1] + h0 + 2), 0, 0.5, (0, 0, 0), 1,
                    cv2.LINE_AA)

    def drawZED(self, im, box, score, class_id, overlay):
        "ç”»zedæ¡†"
        color = self.color_palette[int(class_id)]
        top_left_corner = [box[0], box[1]]
        top_right_corner = [box[2], box[1]]
        bottom_right_corner = [box[2], box[3]]
        bottom_left_corner = [box[0], box[3]]
        # Creation of the 2 horizontal lines
        cv2.line(im, (int(top_left_corner[0]), int(top_left_corner[1])),
                 (int(top_right_corner[0]), int(top_right_corner[1])), color, 3)
        cv2.line(im, (int(bottom_left_corner[0]), int(bottom_left_corner[1])),
                 (int(bottom_right_corner[0]), int(bottom_right_corner[1])), color, 3)
        # Creation of 2 vertical lines
        self.draw_vertical_line(im, bottom_left_corner, top_left_corner, color, 3)
        self.draw_vertical_line(im, bottom_right_corner, top_right_corner, color, 3)
        roi_height = int(top_right_corner[0] - top_left_corner[0])
        roi_width = int(bottom_left_corner[1] - top_left_corner[1])
        overlay_roi = overlay[int(top_left_corner[1]):int(top_left_corner[1] + roi_width)
        , int(top_left_corner[0]):int(top_left_corner[0] + roi_height)]

        overlay_roi[:, :] = color
        p1, p2 = (int(top_left_corner[0]), int(top_left_corner[1])), (
            int(bottom_right_corner[0]), int(bottom_right_corner[1]))

        confidence = str('{:.2f}'.format(score))
        label = f"{self.label_dict[class_id]} {confidence}"
        w0, h0 = cv2.getTextSize(label, 0, 0.5, 1)[0]
        outside = p1[1] - h0 >= 3
        p2 = p1[0] + w0 + w0 // 4, p1[1] - h0 - 3 if outside else p1[1] + h0 + 3
        cv2.rectangle(im, p1, p2, color, -1, cv2.LINE_AA)

        cv2.putText(im, label, (p1[0], p1[1] - 2 if outside else p1[1] + h0 + 2),
                    cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.8, (0, 0, 0), 1, cv2.LINE_AA)

    def sigmoid(self, x):
        return 1. / (1. + np.exp(-x))

    def draw_vertical_line(self, left_display, start_pt, end_pt, clr, thickness):
        "ç”»å‚ç›´çº¿"
        n_steps = 7
        pt1 = [((n_steps - 1) * start_pt[0] + end_pt[0]) / n_steps, ((n_steps - 1) * start_pt[1] + end_pt[1]) / n_steps]
        pt4 = [(start_pt[0] + (n_steps - 1) * end_pt[0]) / n_steps, (start_pt[1] + (n_steps - 1) * end_pt[1]) / n_steps]

        cv2.line(left_display, (int(start_pt[0]), int(start_pt[1])), (int(pt1[0]), int(pt1[1])), clr, thickness)
        cv2.line(left_display, (int(pt4[0]), int(pt4[1])), (int(end_pt[0]), int(end_pt[1])), clr, thickness)

    # for masks2segments
    def draw_axis(self, img, p, q, color, scale):
        angle = np.arctan2(p[1] - q[1], p[0] - q[0])  # è®¡ç®—è§’åº¦
        hypotenuse = np.sqrt((p[1] - q[1]) ** 2 + (p[0] - q[0]) ** 2)  # è®¡ç®—æ–œè¾¹é•¿åº¦

        # æ”¾å¤§ç®­å¤´é•¿åº¦
        q = (int(p[0] - scale * hypotenuse * np.cos(angle)),
             int(p[1] - scale * hypotenuse * np.sin(angle)))

        # ç”»ä¸»è½´çº¿
        cv2.line(img, p, q, color, 1, cv2.LINE_AA)

        # ç”»ç®­å¤´
        p1 = (int(q[0] + 9 * np.cos(angle + np.pi / 4)),
              int(q[1] + 9 * np.sin(angle + np.pi / 4)))
        cv2.line(img, q, p1, color, 1, cv2.LINE_AA)

        p2 = (int(q[0] + 9 * np.cos(angle - np.pi / 4)),
              int(q[1] + 9 * np.sin(angle - np.pi / 4)))
        cv2.line(img, q, p2, color, 1, cv2.LINE_AA)

    def get_orientation(self, pts, img=None):
        # ç¡®ä¿è½®å»“ç‚¹æ˜¯äºŒç»´æµ®ç‚¹å‹æ•°ç»„
        data_pts = np.array(pts, dtype=np.float64).reshape(-1, 2)
        # è®¡ç®—è½®å»“çš„è´¨å¿ƒ
        mean = np.mean(data_pts, axis=0)
        data_pts -= mean
        # PCA ä¸»æˆåˆ†åˆ†æ
        _, eigenvectors, _ = cv2.PCACompute2(data_pts, mean=None)
        return eigenvectors[0]  # è¿”å›ä¸»è½´æ–¹å‘çš„å‘é‡

    def find_adjacent_min_distances(self, contours):
        min_distances = []
        for i in range(len(contours) - 1):
            # è®¡ç®—ç›¸é‚»è½®å»“ä¹‹é—´çš„æœ€çŸ­è·ç¦»
            dists = cdist(contours[i].reshape(-1, 2), contours[i + 1].reshape(-1, 2))
            min_distance = dists.min()  # è·å–æœ€çŸ­è·ç¦»
            min_distances.append(min_distance)

        return min_distances

    def calculate_angle(self, vec1, vec2):
        """è®¡ç®—è½®å»“çš„è§’åº¦å·®å¼‚"""
        dot_product = np.dot(vec1, vec2)
        magnitude1 = np.linalg.norm(vec1)
        magnitude2 = np.linalg.norm(vec2)
        cos_theta = dot_product / (magnitude1 * magnitude2)
        # å¤¹è§’è®¡ç®—ï¼Œå¼§åº¦è½¬ä¸ºè§’åº¦
        angle = np.arccos(cos_theta)
        return np.degrees(angle)

    def alpha_shape(self, points, alpha):
        """
        è®¡ç®—ç‚¹é›†çš„Alpha Shapeï¼ˆå‡¹åŒ…ç»œï¼‰ã€‚
        :param points: ç‚¹çš„é›†åˆ (n, 2)ã€‚
        :param alpha: Alpha å‚æ•°ï¼Œå†³å®šå‡¹åŒ…ç»œçš„ç´§è‡´ç¨‹åº¦ã€‚
        :return: åŒ…ç»œè¾¹ç•Œçš„ç‚¹å¯¹é›†åˆã€‚
        """
        if len(points) < 4:
            # å¦‚æœåªæœ‰ä¸‰ä¸ªç‚¹ï¼Œç›´æ¥è¿”å›å‡¸åŒ…
            return Delaunay(points).convex_hull

        tri = Delaunay(points)
        edges = set()
        for ia, ib, ic in tri.simplices:
            a = np.linalg.norm(points[ia] - points[ib])
            b = np.linalg.norm(points[ib] - points[ic])
            c = np.linalg.norm(points[ic] - points[ia])
            s = (a + b + c) / 2.0
            area = np.sqrt(s * (s - a) * (s - b) * (s - c))
            circum_r = a * b * c / (4.0 * area)
            if circum_r < 1.0 / alpha:
                edges.add(tuple(sorted([ia, ib])))
                edges.add(tuple(sorted([ib, ic])))
                edges.add(tuple(sorted([ic, ia])))
        return np.array(list(edges))


class Build_TRT_model():
    def __init__(self, weight):
        with open(weight, "rb") as f:
            engineString = f.read()
        logger = trt.Logger(trt.Logger.WARNING)
        engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)
        self.tensorname = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]
        self.context = engine.create_execution_context()
        self.nIO = engine.num_io_tensors
        self.nInput = [engine.get_tensor_mode(self.tensorname[i]) for i in range(self.nIO)].count(
            trt.TensorIOMode.INPUT)  # 1ä¸ªè¾“å…¥
        self.dtypes = trt.nptype(engine.get_tensor_dtype(self.tensorname[0]))
        self.input_shapes = [
            engine.get_tensor_shape(self.tensorname[i])
            for i in range(self.nIO)
            if engine.get_tensor_mode(self.tensorname[i]) == trt.TensorIOMode.INPUT
        ]
        print('Load engine success')

    def __call__(self, image):
        # å‡†å¤‡è¾“å…¥æ•°æ®
        bufferH = [image]
        # ä¸ºè¾“å‡ºæ•°æ®åˆ†é…å†…å­˜ 2ä¸ªè¾“å‡º
        for i in range(self.nInput, self.nIO):
            bufferH.append(np.empty(self.context.get_tensor_shape(self.tensorname[i]), self.dtypes))
        # ä¸ºGPUåˆ†é…å†…å­˜
        bufferD = []
        for i in range(self.nIO):
            bufferD.append(cudart.cudaMalloc(bufferH[i].nbytes)[1])
        # å°†æ•°æ®ä»ä¸»æœºç«¯å¤åˆ¶åˆ°è®¾å¤‡ç«¯
        for i in range(self.nInput):
            cudart.cudaMemcpy(bufferD[i], bufferH[i].ctypes.data, bufferH[i].nbytes,
                              cudart.cudaMemcpyKind.cudaMemcpyHostToDevice)
        for i in range(self.nIO):
            self.context.set_tensor_address(self.tensorname[i], int(bufferD[i]))
        self.context.execute_async_v3(0)
        # å°†æ•°æ®ä»è®¾å¤‡ç«¯å¤åˆ¶åˆ°ä¸»æœºç«¯
        for i in range(self.nInput, self.nIO):
            cudart.cudaMemcpy(bufferH[i].ctypes.data, bufferD[i], bufferH[i].nbytes,
                              cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost)
        for buf in bufferD:
            cudart.cudaFree(buf)  # é‡Šæ”¾,ä¸ç„¶è¦ç‚¸
        return bufferH[1:]


class Build_Ort_model():
    def __init__(self, weight):
        self.session = ort.InferenceSession(weight, providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
        if ort.get_device() == 'GPU' else ['CPUExecutionProvider'])
        print(f"Load onnx success, using {ort.get_device()}")
        self.dtypes = np.half if self.session.get_inputs()[0].type == 'tensor(float16)' else np.single
        self.input_shapes = [self.session._inputs_meta[0].shape]

    def __call__(self, image):
        res = self.session.run(None, {self.session.get_inputs()[0].name: image})
        return res


class My_LoggerConfig:
    def __init__(self, name='xy', level=logging.INFO):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)
        self._configure_handler()

    def _configure_handler(self):
        # åˆ›å»ºä¸€ä¸ªå¤„ç†å™¨ï¼Œç”¨äºå°†æ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å°
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)

        # åˆ›å»ºä¸€ä¸ªå½©è‰²æ ¼å¼åŒ–å™¨
        formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(levelname)s - %(name)s | - %(message_log_color)s%(message)s",
            datefmt=None,
            reset=True,
            log_colors={
                'DEBUG': 'cyan',
                'INFO': 'green',
                'WARNING': 'yellow',
                'ERROR': 'red',
                'CRITICAL': 'red,bg_white',
            },
            secondary_log_colors={
                'message': {
                    'DEBUG': 'white',
                    'INFO': 'blue',
                    'WARNING': 'purple',
                    'ERROR': 'bg_red',
                    'CRITICAL': 'bg_red',
                }
            }
        )

        # å°†æ ¼å¼åŒ–å™¨æ·»åŠ åˆ°å¤„ç†å™¨
        console_handler.setFormatter(formatter)

        # å°†å¤„ç†å™¨æ·»åŠ åˆ°è®°å½•å™¨
        self.logger.addHandler(console_handler)

    def get_logger(self):
        return self.logger
