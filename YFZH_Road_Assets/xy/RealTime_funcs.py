# -*- coding: utf-8 -*-
# @Time    : 2024/5/20 5:20
# @Author  : XianYangğŸš€
# @Email   : xy_mts@163.com
# @File    : RealTime_funcs.py
# ------â¤â¤â¤------ #

import datetime
import json
import os
import platform
import queue
import re
import signal
import socket
import subprocess
import subprocess as sp
import sys
import threading
import time
import traceback

import cv2
import numpy as np
from pyzed import sl

from .get_result import get_det_result, get_seg_result
from .tracker.byte_tracker import BYTETracker

message_queue = queue.Queue()
DATA = {'txt': '../output_folder/detect_svo_socker_Plus',
        'video': '../output_folder/detect_svo_socker_Plus',
        'svo': '../output_folder/detect_svo_socker_Plus',
        'taskId': 'test',
        'command': 'nothing'}


# region
# è·å–ip
def get_ip_addresses():
    # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
    system = platform.system()
    if system == "Windows":
        # Windows ä½¿ç”¨ ipconfig
        result = subprocess.run(['ipconfig'], capture_output=True, text=True)
        output = result.stdout
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ‰€æœ‰ IPv4 åœ°å€
        ip_pattern = r'IPv4 åœ°å€[. ]*: (\d+\.\d+\.\d+\.\d+)'
    else:
        # Linux æˆ– Mac ä½¿ç”¨ ifconfig
        result = subprocess.run(['ifconfig'], capture_output=True, text=True)
        output = result.stdout
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ‰€æœ‰ IP åœ°å€
        ip_pattern = r'inet (\d+\.\d+\.\d+\.\d+)'

    # æŸ¥æ‰¾åŒ¹é…çš„ IP åœ°å€
    matches = re.findall(ip_pattern, output)
    # æ’é™¤å›ç¯åœ°å€
    return [ip for ip in matches if ip != '127.0.0.1']


# è·Ÿè¸ªiouåŒºåˆ†
def iou(box: np.ndarray, boxes: np.ndarray):
    xy_max = np.minimum(boxes[:, 2:], box[2:])
    xy_min = np.maximum(boxes[:, :2], box[:2])
    inter = np.clip(xy_max - xy_min, a_min=0, a_max=np.inf)
    inter = inter[:, 0] * inter[:, 1]

    area_boxes = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    area_box = (box[2] - box[0]) * (box[3] - box[1])

    return inter / (area_box + area_boxes - inter)


# åˆå§‹åŒ–ç›¸æœºï¼Œæ²¡æœ‰é€’å¢ç›®å½•
def init_camera_socket(opt, svo_real_time_mode=True):
    zed = sl.Camera()
    if opt.path != 'camera':
        input_type = sl.InputType()
        input_type.set_from_svo_file(str(opt.path.resolve()))  # å¾—åˆ°ç»å¯¹è·¯å¾„
        init_params = sl.InitParameters(input_t=input_type,
                                        svo_real_time_mode=svo_real_time_mode)  ## svo_real_time_modeè®¾ç½®ä¸ºFalseåï¼Œä¼šå¤„ç†æ¯ä¸€å¸§
    else:
        init_params = sl.InitParameters(svo_real_time_mode=svo_real_time_mode)
        init_params.camera_resolution = sl.RESOLUTION.HD1080

    init_params.coordinate_units = sl.UNIT.METER
    init_params.depth_mode = sl.DEPTH_MODE.NEURAL
    init_params.coordinate_system = sl.COORDINATE_SYSTEM.LEFT_HANDED_Y_UP
    init_params.depth_maximum_distance = 50

    runtime_params = sl.RuntimeParameters()
    status = zed.open(init_params)
    if status != sl.ERROR_CODE.SUCCESS:
        print(repr(status))
        exit()
    else:
        print('Local File Total Frame: ', zed.get_svo_number_of_frames())

    positional_tracking_parameters = sl.PositionalTrackingParameters()
    zed.enable_positional_tracking(positional_tracking_parameters)
    obj_param = sl.ObjectDetectionParameters()
    obj_param.detection_model = sl.OBJECT_DETECTION_MODEL.CUSTOM_BOX_OBJECTS
    obj_param.enable_tracking = True

    zed.enable_object_detection(obj_param)
    objects = sl.Objects()
    obj_runtime_param = sl.ObjectDetectionRuntimeParameters()

    camera_infos = zed.get_camera_information()
    camera_res = camera_infos.camera_configuration.resolution
    point_cloud_res = sl.Resolution(min(camera_res.width, 1920), min(camera_res.height, 1080))
    point_cloud = sl.Mat(point_cloud_res.width, point_cloud_res.height, sl.MAT_TYPE.F32_C4, sl.MEM.CPU)  # ç‚¹äº‘å®¹å™¨
    cam_w_pose = sl.Pose()  # å§¿æ€å®¹å™¨
    sensors_data = sl.SensorsData()  # ä¼ æ„Ÿå™¨å®¹å™¨
    py_orientation = sl.Orientation()  # è§’
    image_left_tmp = sl.Mat()  # è£…imageçš„å®¹å™¨
    return (zed, runtime_params, image_left_tmp, sensors_data,
            point_cloud, point_cloud_res, cam_w_pose, py_orientation, objects, obj_runtime_param)


# å‘é€æ¶ˆæ¯
def send_messages(sock):
    while True:
        try:
            message = message_queue.get()  # ä»é˜Ÿåˆ—ä¸­è·å–æ¶ˆæ¯
            sock.sendall(message.encode('utf-8'))
        except Exception as e:
            print(f"Error sending data: {e}")
            break


# æ¥æ”¶æ¶ˆæ¯
def receive_messages_rtsp(sock):
    global DATA
    while True:
        try:
            DATA = sock.recv(1024).decode('utf-8')
            if not DATA:
                break
            json_start = DATA.find('{')
            json_end = DATA.rfind('}')
            # æå– JSON å­—ç¬¦ä¸²
            json_str = DATA[json_start:json_end + 1]
            # å°† JSON å­—ç¬¦ä¸²è§£æä¸º Python å­—å…¸
            DATA = json.loads(json_str)
            required_keys = ['txt', 'video', 'svo', 'taskId', 'command']
            missing_keys = [key for key in required_keys if key not in DATA]
            if missing_keys:
                raise ValueError(f"Missing required keys: {missing_keys}")
            print(f"-------------------Received: {DATA}-------------------------")

        except Exception as e:
            print(f"Error receiving data: {e}")
            break


# è·å–æ–‡ä»¶çš„åˆ›å»ºæ—¶é—´
def get_creation_time(file_path):
    return os.path.getctime(file_path)


# åˆå¹¶mp4
def merge_videos_by_creation_time(input_directory, output_file_path, taskId, stop_cont):
    file_list_path = 'filelist.txt'
    mp4_files = [f for f in os.listdir(input_directory) if f.endswith('.mp4')] if os.path.isdir(
        output_file_path) else []
    # æœ‰2ä¸ªmp4å°±åˆå¹¶ä¸€æ¬¡ï¼Œä¹Ÿå¯ä»¥å…¨éƒ¨ä¸€èµ·åˆ
    if len(mp4_files) < 2:
        print("æ–‡ä»¶æ•°é‡ä¸è¶³ä»¥è¿›è¡Œåˆå¹¶ã€‚")
        return
    stop_cont[0] += 1  # æ›´æ–°åˆ—è¡¨ä¸­çš„å€¼
    # æŒ‰åˆ›å»ºæ—¶é—´æ’åºæ–‡ä»¶
    mp4_files.sort(key=lambda f: get_creation_time(os.path.join(input_directory, f)))

    with open(file_list_path, 'w') as file:
        for mp4_file in mp4_files:
            file.write(f"file '{os.path.join(input_directory, mp4_file)}'\n")

    output_file = f"{output_file_path}/{taskId}{stop_cont[0]}.mp4"
    # æ‰§è¡Œ FFmpeg åˆå¹¶
    command = [
        'ffmpeg',
        '-f', 'concat',
        '-safe', '0',
        '-i', file_list_path,
        '-c', 'copy',
        output_file
    ]
    sp.run(command, check=True)
    for mp4_file in mp4_files:
        file_path = os.path.join(input_directory, mp4_file)
        os.remove(file_path)
        print(f"å·²åˆ é™¤æ–‡ä»¶: {file_path}")

    # åˆ é™¤ filelist.txt
    os.remove(file_list_path)

# è·å–å½“å‰å¸§çš„ä¿¡æ¯
def get_current_frame_info(zed, point_cloud, point_cloud_res, cam_w_pose, py_orientation, sensors_data):
    # -- Get the point_cloud
    zed.retrieve_measure(point_cloud, sl.MEASURE.XYZRGBA, sl.MEM.CPU, point_cloud_res)
    # -- Get the ox oy oz ow
    zed.get_position(cam_w_pose, sl.REFERENCE_FRAME.WORLD)
    ox = round(cam_w_pose.get_orientation(py_orientation).get()[0], 3)  # è·å–ZEDç›¸æœºåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„ä½ç½®å’Œå§¿æ€
    oy = round(cam_w_pose.get_orientation(py_orientation).get()[1], 3)
    oz = round(cam_w_pose.get_orientation(py_orientation).get()[2], 3)
    ow = round(cam_w_pose.get_orientation(py_orientation).get()[3], 3)
    # --Get the magnetic_heading
    zed.get_sensors_data(sensors_data, sl.TIME_REFERENCE.CURRENT)  # è·å–ä¼ æ„Ÿå™¨æ•°æ®ï¼ŒæŒ‡å®šæ—¶é—´å‚è€ƒä¸ºå½“å‰æ—¶é—´
    magnetometer_data = sensors_data.get_magnetometer_data()  # æ‹¿åˆ°ç£åŠ›è®¡æ•°æ®ï¼Œå‚¨å­˜åœ¨magnetometer_dataä¸­
    magnetic_heading = round(magnetometer_data.magnetic_heading, 4)  # ç£åŠ›è®¡å€¼å››èˆäº”å…¥
    # -- Get the camera time
    timestamp = int(zed.get_timestamp(sl.TIME_REFERENCE.IMAGE).data_ns / (10 ** 6))
    timeStamp = float(timestamp) / 1000
    ret_datetime = datetime.datetime.utcfromtimestamp(timeStamp).strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
    return ox, oy, oz, ow, magnetic_heading, timeStamp, ret_datetime

# æ•è·ä¸­æ–­
def signal_handler(signal, frame):
    global ffmpeg_proc
    print('Signal received, shutting down gracefully...')
    try:
        # å…³é—­ stdin å¹¶ç­‰å¾… ffmpeg è¿›ç¨‹å®Œæˆ
        if ffmpeg_proc.stdin:
            ffmpeg_proc.stdin.close()  # å…³é—­ stdin è®© ffmpeg çŸ¥é“è¾“å…¥å®Œæˆ
        ffmpeg_proc.wait()  # ç­‰å¾… ffmpeg è¿›ç¨‹å®Œæˆ
        print('FFmpeg process cleaned up.')
    except Exception as e:
        print(f"Error during cleanup: {e}")
    sys.exit(0)  # é€€å‡ºç¨‹åº


signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
# endregion


# æ£€æµ‹svoä½¿ç”¨äº†è·Ÿè¸ªï¼Œä½¿ç”¨äº†trspï¼Œä½¿ç”¨socker
def detect_svo_track_socket_rstp(opt, Model, host, port, rtspUrl):
    global DATA
    # åˆ›å»ºsocketå¯¹è±¡
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        try:
            s.connect((host, port))
            print(f"Connected to {host}:{port}")
        except Exception as e:
            print(f"Could not connect to {host}:{port}: {e}")
            return

        # å¯åŠ¨æ¥æ”¶æ¶ˆæ¯çš„çº¿ç¨‹
        receive_thread = threading.Thread(target=receive_messages_rtsp, args=(s,))
        receive_thread.daemon = True
        receive_thread.start()

        # å¯åŠ¨å‘é€æ¶ˆæ¯çš„çº¿ç¨‹
        send_thread = threading.Thread(target=send_messages, args=(s,))
        send_thread.daemon = True
        send_thread.start()

        main_logic_rtsp(opt, Model, rtspUrl)


# sockeræ”¶å‘å…·ä½“å®ç°
def main_logic_rtsp(opt, Model, rtspUrl):
    global DATA, ffmpeg_proc
    assert opt.path == 'camera', 'must be use camera'
    (zed, runtime_params, image_left_tmp, sensors_data, point_cloud, point_cloud_res, cam_w_pose,
     py_orientation, objects, obj_runtime_param) = init_camera_socket(opt, svo_real_time_mode=True)  # Init camera
    det_tracker = BYTETracker(opt, frame_rate=30)
    seg_tracker = BYTETracker(opt, frame_rate=30)
    command = [
        'ffmpeg',
        # 're',#
        # '-y', # æ— éœ€è¯¢é—®å³å¯è¦†ç›–è¾“å‡ºæ–‡ä»¶
        '-f', 'rawvideo',  # å¼ºåˆ¶è¾“å…¥æˆ–è¾“å‡ºæ–‡ä»¶æ ¼å¼
        '-vcodec', 'rawvideo',  # è®¾ç½®è§†é¢‘ç¼–è§£ç å™¨ã€‚è¿™æ˜¯-codec:vçš„åˆ«å
        '-pix_fmt', 'bgr24',  # è®¾ç½®åƒç´ æ ¼å¼
        '-s', '1920*1080',  # è®¾ç½®å›¾åƒå¤§å°
        '-r', '30',  # è®¾ç½®å¸§ç‡
        '-i', '-',  # è¾“å…¥
        '-c:v', 'libx264',
        '-pix_fmt', 'yuv420p',
        '-preset', 'ultrafast',
        '-f', 'rtsp',  # å¼ºåˆ¶è¾“å…¥æˆ–è¾“å‡ºæ–‡ä»¶æ ¼å¼
        rtspUrl]
    pipe = sp.Popen(command, stdin=sp.PIPE)
    # æ§åˆ¶å˜é‡
    stop_handled = False
    pause_handled = False
    first_message = False
    resume_svo = 1
    resume_mp4 = 0
    creat_path = True
    creat = True
    ffmpeg_proc = None
    new_dir_path = None
    task_old = ''
    stop_cont = [0]
    try:
        while True:
            grab = time.time()
            error_code = zed.grab(runtime_params)
            if error_code == sl.ERROR_CODE.SUCCESS:
                # -- Get the image and info
                zed.retrieve_image(image_left_tmp, sl.VIEW.LEFT)
                image_net = image_left_tmp.get_data()
                image_net = cv2.cvtColor(image_net, cv2.COLOR_RGBA2RGB)
                image_orin = image_net.copy()
                ox, oy, oz, ow, magnetic_heading, timeStamp, ret_datetime = get_current_frame_info(zed, point_cloud,point_cloud_res,cam_w_pose,py_orientation,sensors_data)

                grab_end = time.time()
                pipe.stdin.write(image_net.tostring())  # æ¨æµzedç›¸æœºç”»é¢
                if DATA['command'] == 'start' and error_code == sl.ERROR_CODE.SUCCESS:
                    pause_handled = False
                    stop_handled = False
                    if creat_path:  # mp4å’Œtxtèƒ½å¤Ÿç»­å†™ï¼Œæ¯æ¬¡stopåé‡Šæ”¾èµ„æºã€‚é‡æ–°startåå†æ–°å»ºmp4æ–‡ä»¶ï¼Œtxtä¸å—å½±å“
                        # è§£æDATA
                        resume_mp4 += 1
                        if task_old == '':
                            task_old = DATA['taskId']
                        if task_old != DATA['taskId']:  # æ ¹æ®ä»»åŠ¡æ¥åŒºåˆ«è§†é¢‘çš„ç¼–å·æ˜¯å¦è¿ç»­
                            task_old = DATA['taskId']
                            resume_mp4, resume_svo = 1, 1

                        save_txt_path = f"{DATA['txt']}/txt/AiData.txt"
                        save_video_path = f"{DATA['video']}/Video_{resume_mp4}.mp4"
                        save_svo_path = f"{DATA['svo']}/ZED_.svo"
                        save_imgs_path = None
                        new_dir_path = f"{DATA['video']}/full_mp4/"
                        for path in [save_txt_path, save_video_path, save_svo_path, new_dir_path]:
                            directory = os.path.dirname(path)  # æå–ç›®å½•éƒ¨åˆ†
                            if not os.path.exists(directory) and directory:
                                os.makedirs(directory)

                        ffmpeg_cmd = [
                            'ffmpeg', '-y', '-f', 'rawvideo', '-vcodec', 'rawvideo',
                            '-pix_fmt', 'bgr24', '-s', f'{1920}x{1080}', '-r', str(25),
                            '-i', '-', '-an', '-vcodec', 'mpeg4', '-qscale:v', '6', save_video_path
                        ]  # -qscale:v æ˜¯æ§åˆ¶è§†é¢‘è´¨é‡çš„ä¸€ä¸ªé‡è¦å‚æ•°ï¼Œå–å€¼èŒƒå›´ä¸º 1 åˆ° 31ï¼Œæ•°å€¼è¶Šå°è§†é¢‘è´¨é‡è¶Šé«˜

                        ffmpeg_proc = subprocess.Popen(ffmpeg_cmd, stdin=subprocess.PIPE)
                        file = open(save_txt_path, 'a')
                        creat_path = False

                    if creat:  # svoæ–‡ä»¶ä¸èƒ½ç»­å†™ï¼Œæ¯æ¬¡pauseåéƒ½éœ€è¦é‡æ–°æ–°å»ºå’Œä¿å­˜
                        base_path, filename = os.path.split(save_svo_path)
                        name, ext = os.path.splitext(filename)
                        new_filename = f"{name}{resume_svo}{ext}"
                        new_save_svo_path = os.path.join(base_path, new_filename)
                        print('crate new svo: ', new_save_svo_path)
                        resume_svo += 1
                        recording_param = sl.RecordingParameters(new_save_svo_path, sl.SVO_COMPRESSION_MODE.H264)
                        zed.enable_recording(recording_param)
                        creat = False
                    # region
                    # Infer and get the result
                    det, seg, mask = Model(image_net)
                    # for det track.
                    if len(det[0]) != 0:
                        new_det_output = np.zeros((det[0].shape[0], 7))
                        new_det_output[:, :6] = det[0][:, :6]
                        track_det = det[0].copy()
                        track_det[:, 4] = 0.95
                        tracks = det_tracker.update(track_det[:, :5])
                        # å°†idå’Œæ¡†å¯¹åº”èµ·æ¥
                        for track in tracks:
                            box_iou = iou(track.tlbr, track_det[:, :4])
                            maxindex = np.argmax(box_iou)
                            new_det_output[maxindex, :6] = det[0][maxindex, :6]
                            new_det_output[maxindex, 6] = track.track_id
                        # new_det_output  x1y1x2y2 conf class id
                        # ä¸ºè·Ÿè¸ªä¸¢å¤±çš„æ‰‹åŠ¨åˆ†é…id
                        if 0 in new_det_output[:, 6]:
                            for i in range(len(new_det_output[:, 5])):
                                if new_det_output[:, 6][i] == 0:
                                    new_det_output[:, 6][i] = det_tracker.nextid()
                        det[0] = new_det_output
                    # for seg track
                    if len(seg[0]) != 0:
                        new_seg_output = np.zeros((seg[0][0].shape[0], 7))  # segæ˜¯ä¸ªlist2 seg[0]æ˜¯ä¸ªlist seg[0][0]é‡Œé¢æ˜¯æ¡†
                        # ä½¿ç”¨seg[0][0]å¡«å……ï¼Œç„¶åå†å¡«å……id
                        new_seg_output[:, :5] = seg[0][0][:, :5]
                        new_seg_output[:, 6] = seg[0][0][:, 5]
                        track_seg = seg[0][0].copy()
                        track_seg[:, 4] = 0.95
                        seg_track = seg_tracker.update(track_seg[:, :5])
                        # å°†idå’Œæ¡†å¯¹åº”èµ·æ¥
                        for track in seg_track:
                            box_iou = iou(track.tlbr, track_seg[:, :4])
                            maxindex = np.argmax(box_iou)
                            new_seg_output[maxindex, :5] = seg[0][0][maxindex, :5]
                            new_seg_output[maxindex, 5] = track.track_id
                            new_seg_output[maxindex, 6] = seg[0][0][maxindex, 5]
                        # new_seg_output  x1y1x2y2 conf id class
                        if 0 in new_seg_output[:, 5]:
                            for i in range(len(new_seg_output[:, 5])):
                                if new_seg_output[:, 5][i] == 0:
                                    new_seg_output[:, 5][i] = seg_tracker.nextid()
                        seg[0] = [new_seg_output]
                    # deal img for show
                    bgr_image = Model.my_show_track(det, seg, image_net, svo=True)
                    # write and send sth
                    file.write(f"time:{ret_datetime},{ox} {oy} {oz} {ow} {magnetic_heading}\n")

                    message = 'type:city' + '\n'
                    message += f"time:{ret_datetime},{ox} {oy} {oz} {ow} {magnetic_heading}\n"
                    message += 'label:'

                    send_det_msg = get_det_result(det, point_cloud, file, Model)
                    if send_det_msg != 0 and len(send_det_msg) != 0:
                        message += send_det_msg

                    s_line = get_seg_result(seg, point_cloud, bgr_image, file, Model, ret_datetime)

                    if s_line != 0 and len(s_line) != 0:
                        message += s_line
                    message += '\n'
                    message += '<AI>'
                    message_queue.put(message)
                    # endregion
                    show = time.time()
                    # Put timestamp
                    cv2.putText(bgr_image, str(ret_datetime), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 225), 1, cv2.LINE_AA)

                    # Visualization with opencv
                    global_image = cv2.hconcat([image_orin, bgr_image])
                    cv2.namedWindow('love', cv2.WINDOW_NORMAL)
                    cv2.resizeWindow('love', 900, 300)
                    cv2.imshow("love", global_image)
                    cv2.waitKey(1)
                    # Save video
                    if opt.save_video:
                        ffmpeg_proc.stdin.write(bgr_image.tobytes())

                    # Save picture
                    if opt.save_img:
                        filename = datetime.datetime.utcfromtimestamp(timeStamp).strftime("%Y-%m-%d_%H.%M.%S.%f")[:-3]
                        cv2.imwrite(f"{save_imgs_path}/{filename}.jpg", bgr_image)

                    print(f"grab: {(grab_end - grab) * 1000:6.2f}ms")
                    print(f"show: {(time.time() - show) * 1000:6.2f}ms")
                    print(f"total: {(time.time() - grab) * 1000:6.2f}ms")

                elif DATA['command'] == 'pause' and not pause_handled:
                    cv2.destroyAllWindows()
                    zed.disable_recording()
                    print('Pause ...')
                    creat = True
                    pause_handled = True

                elif DATA['command'] == 'stop' and not stop_handled:
                    zed.disable_recording()
                    cv2.destroyAllWindows()
                    if ffmpeg_proc != None:
                        ffmpeg_proc.stdin.close()
                        ffmpeg_proc.wait()
                        file.close()

                    merge_videos_by_creation_time(DATA['video'], f"{new_dir_path}", DATA['taskId'], stop_cont)
                    creat_path = True
                    creat = True
                    print('Stop ...')
                    stop_handled = True

                elif DATA['command'] == 'exit':
                    break
                # åˆå§‹çŠ¶æ€
                elif DATA['command'] == 'nothing' and not first_message:
                    print('Running ... waite input ...')
                    first_message = True

            if str(error_code) == 'CAMERA MOTION SENSORS NOT DETECTED':
                # å…³é—­ç›¸æœº
                zed.disable_recording()
                # åœæ­¢FFmpegè¿›ç¨‹
                pipe.stdin.close()
                pipe.terminate()
                pipe.wait()  # ç¡®ä¿FFmpegè¿›ç¨‹å®Œå…¨åœæ­¢
                # é‡Šæ”¾mp4å†™å…¥
                ffmpeg_proc.stdin.close()
                ffmpeg_proc.wait()
                file.close()
                # å˜é‡ç½®ä½
                DATA['command'] = 'pause'
                creat = True
                pause_handled = True
                # å°è¯•é‡æ–°è¿æ¥ç›¸æœº
                reconnect_camera_success = False
                while not reconnect_camera_success:
                    if zed.grab(runtime_params) == sl.ERROR_CODE.SUCCESS:
                        print("Camera reconnected, restarting stream...")
                        pipe = sp.Popen(command, stdin=sp.PIPE)  # é‡æ–°å¯åŠ¨FFmpegæ¨æµè¿›ç¨‹
                        reconnect_camera_success = True

    except Exception as e:
        print(f"Error occurred during processing: {e}")
        traceback.print_exc()

    finally:
        zed.disable_recording()
        zed.close()
        try:
            if ffmpeg_proc and ffmpeg_proc.stdin and not ffmpeg_proc.stdin.closed:  # ç¡®è®¤ stdin è¿˜æ²¡å…³é—­
                ffmpeg_proc.stdin.close()
            if ffmpeg_proc and ffmpeg_proc.poll() is None:  # ç¡®è®¤è¿›ç¨‹è¿˜åœ¨è¿è¡Œ
                ffmpeg_proc.wait()
            if pipe and pipe.stdin:
                pipe.stdin.close()
            if pipe:
                pipe.wait()
        except Exception as e:
            print(f"Error during final cleanup: {e}")

