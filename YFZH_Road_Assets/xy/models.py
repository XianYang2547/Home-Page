# -*- coding: utf-8 -*-
# @Time    : 2024/5/20 5:20
# @Author  : XianYangğŸš€
# @Email   : xy_mts@163.com
# @File    : models.py
# ------â¤â¤â¤------ #

import logging
import os
import time
from collections import Counter

from scipy.spatial import Delaunay
from scipy.spatial.distance import cdist

import colorlog
import cupy as cp
import cv2
import numpy as np
import onnxruntime as ort
import tensorrt as trt
from cuda import cudart


os.environ['CUDA_MODULE_LOADING'] = 'LAZY'


class My_dection():
    def __init__(self):
        self.Det_Models = None
        self.Seg_Models = None
        self.conf_threshold = 0.45
        self.iou_threshold = 0.45
        self.label_dict = None
        self.classes = None
        self.color_palette = None
        self.SUF = ('.bmp', '.dng', '.jpeg', '.jpg', '.mpo', '.png', '.tif', '.tiff', '.webp', '.pfm')
        self.logger = My_LoggerConfig().get_logger()

    def __call__(self, image):
        pre_start_time = time.time()
        im, ratio, pad_w, pad_h = self.preprocess(image, [640, 640])
        pre_end_time = time.time()
        # æ¨ç†
        inf_start_time = time.time()
        pred0 = self.Det_Models(im)
        pred1 = self.Seg_Models(im)
        inf_end_time = time.time()
        # åå¤„ç†
        post_start_time = time.time()
        results = self.postprocess(pred0, pred1, im, image, ratio, pad_w, pad_h, self.conf_threshold,
                                   self.iou_threshold)
        post_end_time = time.time()
        # ç»Ÿè®¡æ¨ç†æ—¶é—´ç”¨äºæ‰“å°
        self.message = [(pre_end_time - pre_start_time) * 1000, (inf_end_time - inf_start_time) * 1000,
                        (post_end_time - post_start_time) * 1000]
        return results

    def warm_up(self, n):
        for i in range(n):
            dummy_input = np.random.rand(1, 3, 640, 640).astype(self.Det_Models.dtypes)
            self.Det_Models(dummy_input)
            self.Seg_Models(dummy_input)
        print("Model Warmup " + f"{n}" + " times")

    def preprocess(self, image, img_size):
        "é¢„å¤„ç†"
        img, ratio, (dw, dh) = self.letterbox(image, img_size, stride=32, auto=False)
        # ä½¿ç”¨ CuPy è¿›è¡Œå›¾åƒå¤„ç†
        img_cp = cp.asarray(img)  # å°† NumPy æ•°ç»„è½¬æ¢ä¸º CuPy æ•°ç»„
        img_cp = img_cp[:, :, ::-1].transpose(2, 0, 1)  # è½¬æ¢è‰²å½©ç©ºé—´å¹¶è½¬ç½®ç»´åº¦
        img_cp = cp.ascontiguousarray(img_cp)  # è½¬æ¢ä¸ºè¿ç»­æ•°ç»„
        img_cp = img_cp.astype(cp.float16 if self.Det_Models.dtypes == np.float16 else cp.float32)  # ä½¿ç”¨ CuPy è¿›è¡Œç±»å‹è½¬æ¢
        img_cp /= 255.0  # æ ‡å‡†åŒ–åƒç´ å€¼
        img = cp.asnumpy(img_cp)  # å°† CuPy æ•°ç»„è½¬æ¢å› NumPy æ•°ç»„
        return img[None], ratio, dw, dh  # è¿”å›é¢„å¤„ç†åçš„å›¾åƒå’Œç›¸å…³å‚æ•°

    def letterbox(self, im, new_shape, color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):
        "ç­‰æ¯”ä¾‹ç¼©æ”¾ "
        shape = im.shape[:2]  # current shape [height, width]
        if isinstance(new_shape, int):
            new_shape = (new_shape, new_shape)

        # Scale ratio (new / old)
        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
        if not scaleup:  # only scale down, do not scale up (for better val mAP)
            r = min(r, 1.0)

        # Compute padding
        ratio = r, r  # width, height ratios
        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
        dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding
        if auto:  # minimum rectangle
            dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding
        elif scaleFill:  # stretch
            dw, dh = 0.0, 0.0
            new_unpad = (new_shape[1], new_shape[0])
            ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios

        dw /= 2  # divide padding into 2 sides
        dh /= 2

        if shape[::-1] != new_unpad:  # resize
            im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)
        top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
        left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
        im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border
        return im, ratio, (dw, dh)

    def non_max_suppression(self, prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False,
                            multi_label=False, labels=(), max_det=300, nc=0, max_time_img=0.05, max_nms=30000, max_wh=7680, ):
        # Checks
        assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'
        assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'
        if isinstance(prediction,
                      (list, tuple)):  # YOLOv8 model in validation model, output = (inference_out, loss_out)
            prediction = prediction[0]  # select only inference output

        bs = prediction.shape[0]  # batch size
        nc = nc or (prediction.shape[1] - 4)  # number of classes
        nm = prediction.shape[1] - nc - 4
        mi = 4 + nc  # mask start index
        xc = prediction[:, 4:mi].max(1) > conf_thres  # candidates
        # Settings
        # min_wh = 2  # (pixels) minimum box width and height
        time_limit = 0.5 + max_time_img * bs  # seconds to quit after
        redundant = True  # require redundant detections
        multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)
        merge = False  # use merge-NMS

        output = [np.zeros((0, 6 + nm))] * bs
        for xi, x in enumerate(prediction):  # image index, image inference
            # Apply constraints
            # x[((x[:, 2:4] < min_wh) | (x[:, 2:4] > max_wh)).any(1), 4] = 0  # width-height
            x = x.transpose(1, 0)[xc[xi]]  # confidence

            # Cat apriori labels if autolabelling
            if labels and len(labels[xi]):
                lb = labels[xi]
                v = np.zeros((len(lb), nc + nm + 5))
                v[:, :4] = lb[:, 1:5]  # box
                v[range(len(lb)), lb[:, 0].long() + 4] = 1.0  # cls
                x = np.concatenate((x, v), 0)

            # If none remain process next image
            if not x.shape[0]:
                continue

            # Detections matrix nx6 (xyxy, conf, cls) ndarrayä¸å¥½ç›´æ¥split
            # box, cls, mask = np.split(x,[4, nc, nm], 1)
            box = self.xywh2xyxy(x[:, :4])
            cls = x[:, 4:mi]
            mask = x[:, mi:]

            if multi_label:
                i, j = (cls > conf_thres).nonzero(as_tuple=False).T
                x = np.concatenate((box[i], x[i, 4 + j, None], j[:, None].float(), mask[i]), 1)
            else:  # best class only
                conf = np.max(x[:, 4:mi], 1).reshape(box.shape[:1][0], 1)
                j = np.argmax(x[:, 4:mi], 1).reshape(box.shape[:1][0], 1)
                x = np.concatenate((box, conf, j, mask), 1)[conf.reshape(box.shape[:1][0]) > conf_thres]

            # Filter by class
            if classes is not None:
                x = x[(x[:, 5:6] == np.array(classes, device=x.device)).any(1)]

            # Check shape
            n = x.shape[0]  # number of boxes
            if not n:  # no boxes
                continue
            x = x[x[:, 4].argsort(axis=0)[:max_nms]]  # sort by confidence and remove excess boxes

            # Batched NMS
            c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes
            boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores
            i = self.nms_boxes(boxes, scores)  # NMS
            i = i[:max_det]  # limit detections
            if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)
                # Update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)
                iou = self.box_iou(boxes[i], boxes) > iou_thres  # iou matrix
                weights = iou * scores[None]  # box weights
                x[i, :4] = np.multiply(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes
                if redundant:
                    i = i[iou.sum(1) > 1]  # require redundancy

            output[xi] = x[i]

        return output

    def xywh2xyxy(self, x):
        "ä¸­å¿ƒç‚¹è½¬æ¢"
        y = np.copy(x)
        y[..., 0] = x[..., 0] - x[..., 2] / 2  # top left x
        y[..., 1] = x[..., 1] - x[..., 3] / 2  # top left y
        y[..., 2] = x[..., 0] + x[..., 2] / 2  # bottom right x
        y[..., 3] = x[..., 1] + x[..., 3] / 2  # bottom right y
        return y

    def nms_boxes(self, boxes, scores):
        "NMS"
        x = boxes[:, 0]
        y = boxes[:, 1]
        w = boxes[:, 2] - boxes[:, 0]
        h = boxes[:, 3] - boxes[:, 1]
        areas = w * h
        order = scores.argsort()[::-1]
        keep = []
        while order.size > 0:
            i = order[0]
            keep.append(i)
            xx1 = np.maximum(x[i], x[order[1:]])
            yy1 = np.maximum(y[i], y[order[1:]])
            xx2 = np.minimum(x[i] + w[i], x[order[1:]] + w[order[1:]])
            yy2 = np.minimum(y[i] + h[i], y[order[1:]] + h[order[1:]])
            w1 = np.maximum(0.0, xx2 - xx1 + 0.00001)
            h1 = np.maximum(0.0, yy2 - yy1 + 0.00001)
            inter = w1 * h1
            ovr = inter / (areas[i] + areas[order[1:]] - inter)
            inds = np.where(ovr <= 0.45)[0]
            order = order[inds + 1]
        keep = np.array(keep)
        return keep

    def box_iou(self, box1, box2, eps=1e-7):
        (a1, a2), (b1, b2) = box1.unsqueeze(1).chunk(2, 2), box2.unsqueeze(0).chunk(2, 2)
        inter = (np.min(a2, b2) - np.max(a1, b1)).clamp(0).prod(2)
        return inter / ((a2 - a1).prod(2) + (b2 - b1).prod(2) - inter + eps)

    def postprocess(self, pred0, pred1, im0, image, ratio, pad_w, pad_h, conf_threshold, iou_threshold, nm=32):
        pass

    def scale_mask(self, masks, im0_shape, ratio_pad=None):
        im1_shape = masks.shape[:2]
        if ratio_pad is None:  # calculate from im0_shape
            gain = min(im1_shape[0] / im0_shape[0], im1_shape[1] / im0_shape[1])  # gain  = old / new
            pad = (im1_shape[1] - im0_shape[1] * gain) / 2, (im1_shape[0] - im0_shape[0] * gain) / 2  # wh padding
        else:
            pad = ratio_pad[1]

        # Calculate tlbr of mask
        top, left = int(round(pad[1] - 0.1)), int(round(pad[0] - 0.1))  # y, x
        bottom, right = int(round(im1_shape[0] - pad[1] + 0.1)), int(round(im1_shape[1] - pad[0] + 0.1))
        if len(masks.shape) < 2:
            raise ValueError(f'"len of masks shape" should be 2 or 3, but got {len(masks.shape)}')
        masks = masks[top:bottom, left:right]
        masks = cv2.resize(masks, (im0_shape[1], im0_shape[0]),
                           interpolation=cv2.INTER_LINEAR)  # INTER_CUBIC would be better
        if len(masks.shape) == 2:
            masks = masks[:, :, None]
        return masks

    def postprocess_det(self, preds, img, org_img, conf_thres, iou_thres):
        pred0 = self.non_max_suppression(preds, conf_thres, iou_thres)
        for i, pred in enumerate(pred0):
            pred[:, :4] = self.scale_boxes(img.shape[2:], pred[:, :4], org_img.shape)
            return pred[:, :6]

    def scale_boxes(self, img1_shape, boxes, img0_shape, ratio_pad=None):
        if ratio_pad is None:  # calculate from img0_shape
            gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new
            pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding
        else:
            gain = ratio_pad[0][0]
            pad = ratio_pad[1]
        boxes[..., [0, 2]] -= pad[0]  # x padding
        boxes[..., [1, 3]] -= pad[1]  # y padding
        boxes[..., :4] /= gain
        self.clip_boxes(boxes, img0_shape)
        return boxes

    def clip_boxes(self, boxes, shape):
        # Clip boxes (xyxy) to image shape (height, width)
        boxes[..., [0, 2]] = boxes[..., [0, 2]].clip(0, shape[1])  # x1, x2
        boxes[..., [1, 3]] = boxes[..., [1, 3]].clip(0, shape[0])  # y1, y2

    def my_show(self, det, seg, im, zed_show=False):
        s = 'Result: '
        if len(det) != 0:
            if zed_show:  # ZEDé£æ ¼
                overlay = im.copy()
                for i in det[0]:
                    x1, y1, x2, y2, score, class_id = i
                    self.drawZED(im, [x1, y1, x2, y2], score, class_id, overlay)
                cv2.addWeighted(im, 0.7, overlay, 0.3, 0.0, im)
            else:  # YOLOé£æ ¼  è€—æ—¶æ¯”zedå¿«ä¸€åŠ
                for i in det[0]:
                    x1, y1, x2, y2, score, class_id = i
                    self.drawYOLO(im, [x1, y1, x2, y2], score, class_id)
            for count, element in [(j, self.label_dict[i]) for i, j in
                                   Counter([int(result[-1]) for result in det[0]]).items()]:
                s += f"{element}*{count} "

        if len(seg[0]) != 0:
            bboxes, segments = seg[0], seg[1]
            for count, element in [(j, self.classes[i]) for i, j in
                                   Counter([int(result[-1]) for result in bboxes[0]]).items()]:
                s += f"{element}*{count} "
            im_canvas = im.copy()
            for (*box, conf, cls_), segment in zip(bboxes[0], segments[0]):
                cv2.polylines(im, np.int32([segment]), True,
                              self.color_palette[int(cls_) + len(self.label_dict)], 2)
                # cv2.rectangle(im, [int(num) for num in box][:2], [int(num) for num in box][2:],
                #               self.color_palette[int(cls_) + len(self.label_dict)], 2)
                cv2.putText(im, f'{self.classes[cls_]}:{conf:.3f}',
                            (int(box[0] + (box[2] - box[0]) / 2), int(box[1] + (box[3] - box[1]) / 2)),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.75,
                            self.color_palette[int(cls_) + len(self.label_dict)], thickness=2)
                cv2.fillPoly(im_canvas, np.int32([segment]),
                             self.color_palette[int(cls_) + len(self.label_dict)])

            im = cv2.addWeighted(im_canvas, 0.3, im, 0.7, 0)
        message = f"ğŸš€ğŸš€ğŸš€ Total:{(self.message[0] + self.message[1] + self.message[2]):6.2f}ms," \
                  f" Pre:{self.message[0]:6.2f}ms," \
                  f" Infer:{self.message[1]:6.2f}ms," \
                  f" Post:{self.message[2]:6.2f}ms - | \033[95m{s}\033[0m"
        self.logger.info(message)
        return im

    def my_show_track(self, det, seg, im):
        s = 'Result: '
        if len(det) != 0:
            for i in det[0]:
                if np.all(i == 0):  # è¿‡æ»¤æ‰å…¨0çš„
                    continue
                x1, y1, x2, y2, score, class_id, track_id = i
                self.drawYOLO(im, [x1, y1, x2, y2], score, class_id, track_id)
            for count, element in [(j, self.label_dict[i]) for i, j in
                                   Counter([int(result[-2]) for result in det[0]]).items()]:  # -2æ‰æ˜¯ç±»åˆ« -1æ˜¯id
                s += f"{element}*{count} "

        if len(seg[0]) != 0:
            bboxes, segments = seg[0], seg[1]
            for count, element in [(j, self.classes[i]) for i, j in
                                   Counter([int(result[-1]) for result in bboxes[0]]).items()]:
                s += f"{element}*{count} "
            im_canvas = im.copy()
            for (*box, conf, track_id, cls_), segment in zip(bboxes[0], segments[0]):
                if int(cls_) != 0:
                    cv2.polylines(im, np.int32([segment]), True,
                                  self.color_palette[int(cls_) + len(self.label_dict)], 2)
                    # cv2.rectangle(im, [int(num) for num in box][:2], [int(num) for num in box][2:],
                    #               self.color_palette[int(cls_) + len(self.label_dict)], 2)
                    # cv2.putText(im, f'{self.classes[cls_]}:{conf:.3f} ID: {int(track_id)}',
                    #             ([int(num) for num in box][0], [int(num) for num in box][1] - 2),
                    #             cv2.FONT_HERSHEY_SIMPLEX, 0.75,
                    #             self.color_palette[int(cls_) + len(self.label_dict)], thickness=2)
                    cv2.putText(im, f'{self.classes[cls_]}:{conf:.3f} ID: {int(track_id)}',
                                (int(box[0] + (box[2] - box[0]) / 2), int(box[1] + (box[3] - box[1]) / 2)),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.75,
                                self.color_palette[int(cls_) + len(self.label_dict)], thickness=2)
                    cv2.fillPoly(im_canvas, np.int32([segment]),
                                 self.color_palette[int(cls_) + len(self.label_dict)])
                if int(cls_) == 0:  # è½¦é“çº¿
                    cv2.putText(im, f'{self.classes[cls_]}:{conf:.3f} ID: {int(track_id)}',
                                (int(box[0] + (box[2] - box[0]) / 2), int(box[1] + (box[3] - box[1]) / 2)),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), thickness=2)
                    # cv2.polylines(im, np.int32([segment]), True, (255, 0, 255), 2)
                    # cv2.fillPoly(im_canvas, np.int32([segment]),
                    #              self.color_palette[int(cls_) + len(self.label_dict)])


            im = cv2.addWeighted(im_canvas, 0.3, im, 0.7, 0)
        message = f"ğŸš€ğŸš€ğŸš€ Total:{(self.message[0] + self.message[1] + self.message[2]):6.2f}ms," \
                  f" Pre:{self.message[0]:6.2f}ms," \
                  f" Infer:{self.message[1]:6.2f}ms," \
                  f" Post:{self.message[2]:6.2f}ms - | \033[95m{s}\033[0m"
        self.logger.info(message)

        return im

    def my_show_yellow_color(self, det, seg, im, svo=False, zed_show=False):
        s = 'Result: '
        if len(det) != 0:
            if zed_show:  # ZEDé£æ ¼
                overlay = im.copy()
                for i in det[0]:
                    x1, y1, x2, y2, score, class_id = i
                    self.drawZED(im, [x1, y1, x2, y2], score, class_id, overlay)
                cv2.addWeighted(im, 0.7, overlay, 0.3, 0.0, im)
            else:  # YOLOé£æ ¼
                for i in det[0]:
                    x1, y1, x2, y2, score, class_id = i
                    self.drawYOLO(im, [x1, y1, x2, y2], score, class_id)
            for count, element in [(j, self.label_dict[i]) for i, j in
                                   Counter([int(result[-1]) for result in det[0]]).items()]:
                s += f"{element}*{count} "

        if len(seg[0]) != 0:
            bboxes, segments = seg[0], seg[1]
            for count, element in [(j, self.classes[i]) for i, j in
                                   Counter([int(result[-1]) for result in bboxes[0]]).items()]:
                s += f"{element}*{count} "
            im_canvas = im.copy()
            for (*box, conf, cls_), segment in zip(bboxes[0], segments[0]):
                if svo:
                    points = np.int32(segment)
                    mask = np.zeros(im.shape[:2], dtype=np.uint8)
                    cv2.fillPoly(mask, [points], 255)
                    # è™šå®
                    img = cv2.bitwise_and(im, im, mask=mask)
                    # å°†å›¾åƒè½¬æ¢ä¸ºäºŒç»´æ•°ç»„ï¼Œæ¯ä¸ªåƒç´ ç‚¹ä¸ºä¸€ä¸ªä¸‰ç»´ï¼ˆRGBï¼‰å‘é‡
                    pixels = img.reshape((-1, 3))
                    pixels = np.float32(pixels)
                    # ä½¿ç”¨K-meansèšç±»æ¥åˆ†å‰²é¢œè‰²
                    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)
                    k = 3  # èšç±»çš„ç±»æ•°ï¼Œå‡è®¾æœ‰3ç§ä¸åŒé¢œè‰²çš„å—
                    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
                    # å°†ä¸­å¿ƒç‚¹è½¬æ¢ä¸ºæ•´æ•°ï¼ˆRGBé¢œè‰²å€¼ï¼‰
                    centers = np.uint8(centers)
                    # æ ¹æ®æ ‡ç­¾é‡å»ºé‡åŒ–åçš„å›¾åƒ
                    quantized_img = centers[labels.flatten()]
                    quantized_img = quantized_img.reshape(img.shape)
                    # å°†æ¯ä¸€ä¸ªèšç±»ç»“æœè½¬åŒ–ä¸ºç‹¬ç«‹çš„è‰²å—æ©ç 
                    masks = [cv2.inRange(quantized_img, centers[i], centers[i]) for i in range(k)]

                    # è®¡ç®—æ¯ä¸ª mask ä¸­éé›¶åƒç´ çš„æ•°é‡ï¼ˆå³è‰²å—é¢ç§¯ï¼‰
                    mask_areas = [np.count_nonzero(mask) for mask in masks]
                    # å›¾åƒæ€»é¢ç§¯
                    total_area = img.shape[0] * img.shape[1]
                    # è®¾ç½®ä¸€ä¸ªé¢ç§¯ä¸Šé™æ¯”ä¾‹ï¼Œæ¯”å¦‚å¤§äº 80% è§†ä¸ºèƒŒæ™¯
                    background_threshold = 0.8 * total_area
                    # è®¾ç½®æœ€å°é¢ç§¯é˜ˆå€¼ï¼Œæ¯”å¦‚å°äº 500 åƒç´ çš„è‰²å—ä¸ä¿ç•™
                    min_area_threshold = 800
                    # è¿‡æ»¤æ‰èƒŒæ™¯å’Œé¢ç§¯å°äº 500 çš„ mask
                    filtered_masks = [mask for mask, area in zip(masks, mask_areas) if
                                      background_threshold > area > min_area_threshold]
                    # å®çº¿çš„np.count_nonzeroå‰æ™¯æ¯”èƒŒæ™¯å¤§

                    # ç»Ÿè®¡æ¯ä¸ªèšç±»ä¸­çš„è‰²å—æ•°é‡ï¼Œå¹¶è¿‡æ»¤è¾ƒå°é¢ç§¯çš„è‰²å—
                    # å¯¹æ¯ä¸ªè‰²å—æ©ç è¿›è¡Œè½®å»“æ£€æµ‹
                    block_counts = []
                    for i, mask in enumerate(filtered_masks):
                        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        block_counts.append(len(contours))
                        # æ˜¾ç¤ºæ¯ä¸ªèšç±»åçš„è‰²å—
                        color_img = cv2.bitwise_and(img, img, mask=mask)
                        # cv2.imshow(f'Color Block {i + 1}', color_img)

                    # åˆ¤æ–­æ˜¯å¦ä¸ºè™šçº¿
                    for i, count in enumerate(block_counts):
                        print(f'Color Block {i + 1} has {count} contours.')
                    if max(block_counts) > 1:
                        linetype='dashed line'
                    else:
                        linetype='solid line'

                    # é¢œè‰²
                    mean_color = cv2.mean(im, mask=mask)[:3]
                    mean_bgr = np.array(mean_color, dtype=np.uint8).reshape(1, 1, 3)
                    mean_hsv = cv2.cvtColor(mean_bgr, cv2.COLOR_BGR2HSV).flatten()
                    hue, saturation, value = mean_hsv  # è‰²è°ƒ é¥±å’Œåº¦ äº®åº¦
                    is_yellow = (15 <= hue <= 45) and (saturation > 25) and (value > 70)

                    cv2.polylines(im, np.int32([segment]), True,
                                  self.color_palette[int(cls_) + len(self.label_dict)], 2)

                    cv2.putText(im, f'{self.classes[cls_]}:{conf:.3f} {is_yellow} {linetype}',
                                (int(box[0] + (box[2] - box[0]) / 2), int(box[1] + (box[3] - box[1]) / 2)),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.75,
                                self.color_palette[int(cls_) + len(self.label_dict)], thickness=2)

                else:
                    cv2.polylines(im, np.int32([segment]), True, (255, 255, 255), 2)
                    cv2.fillPoly(im_canvas, np.int32([segment]),
                                 self.color_palette[int(cls_) + len(self.label_dict)])  # fixme segment ä¸ºç©ºå¥½åƒæŠ¥é”™
            im = cv2.addWeighted(im_canvas, 0.3, im, 0.7, 0)
        message = f"ğŸš€ğŸš€ğŸš€Pre:{self.message[0]:6.2f}ms, Infer:{self.message[1]:6.2f}ms, Post:{self.message[2]:6.2f}ms - | \033[95m{s}\033[0m"
        self.logger.info(message)

        return im

    def drawYOLO(self, im0, box, score, class_id, track_id=None):
        "ç”»yoloæ¡†"
        color = self.color_palette[int(class_id)]
        p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))
        cv2.rectangle(im0, p1, p2, color, 2)
        label = f'{self.label_dict[class_id]}: {score:.2f} ID: {int(track_id)}' if track_id else f'{self.label_dict[class_id]}: {score:.2f}'
        w0, h0 = cv2.getTextSize(label, 0, 0.5, 1)[0]
        outside = p1[1] - h0 >= 3
        p2 = p1[0] + w0, p1[1] - h0 - 3 if outside else p1[1] + h0 + 3
        cv2.rectangle(im0, p1, p2, color, -1, cv2.LINE_AA)
        cv2.putText(im0, label, (p1[0], p1[1] - 2 if outside else p1[1] + h0 + 2), 0, 0.5, (0, 0, 0), 1,
                    cv2.LINE_AA)

    def drawZED(self, im, box, score, class_id, overlay):
        "ç”»zedæ¡†"
        color = self.color_palette[int(class_id)]
        top_left_corner = [box[0], box[1]]
        top_right_corner = [box[2], box[1]]
        bottom_right_corner = [box[2], box[3]]
        bottom_left_corner = [box[0], box[3]]
        # Creation of the 2 horizontal lines
        cv2.line(im, (int(top_left_corner[0]), int(top_left_corner[1])),
                 (int(top_right_corner[0]), int(top_right_corner[1])), color, 3)
        cv2.line(im, (int(bottom_left_corner[0]), int(bottom_left_corner[1])),
                 (int(bottom_right_corner[0]), int(bottom_right_corner[1])), color, 3)
        # Creation of 2 vertical lines
        self.draw_vertical_line(im, bottom_left_corner, top_left_corner, color, 3)
        self.draw_vertical_line(im, bottom_right_corner, top_right_corner, color, 3)
        roi_height = int(top_right_corner[0] - top_left_corner[0])
        roi_width = int(bottom_left_corner[1] - top_left_corner[1])
        overlay_roi = overlay[int(top_left_corner[1]):int(top_left_corner[1] + roi_width)
        , int(top_left_corner[0]):int(top_left_corner[0] + roi_height)]

        overlay_roi[:, :] = color
        p1, p2 = (int(top_left_corner[0]), int(top_left_corner[1])), (
            int(bottom_right_corner[0]), int(bottom_right_corner[1]))

        confidence = str('{:.2f}'.format(score))
        label = f"{self.label_dict[class_id]} {confidence}"
        w0, h0 = cv2.getTextSize(label, 0, 0.5, 1)[0]
        outside = p1[1] - h0 >= 3
        p2 = p1[0] + w0 + w0 // 4, p1[1] - h0 - 3 if outside else p1[1] + h0 + 3
        cv2.rectangle(im, p1, p2, color, -1, cv2.LINE_AA)

        cv2.putText(im, label, (p1[0], p1[1] - 2 if outside else p1[1] + h0 + 2),
                    cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.8, (0, 0, 0), 1, cv2.LINE_AA)

    def sigmoid(self, x):
        return 1. / (1. + np.exp(-x))

    def draw_vertical_line(self, left_display, start_pt, end_pt, clr, thickness):
        "ç”»å‚ç›´çº¿"
        n_steps = 7
        pt1 = [((n_steps - 1) * start_pt[0] + end_pt[0]) / n_steps, ((n_steps - 1) * start_pt[1] + end_pt[1]) / n_steps]
        pt4 = [(start_pt[0] + (n_steps - 1) * end_pt[0]) / n_steps, (start_pt[1] + (n_steps - 1) * end_pt[1]) / n_steps]

        cv2.line(left_display, (int(start_pt[0]), int(start_pt[1])), (int(pt1[0]), int(pt1[1])), clr, thickness)
        cv2.line(left_display, (int(pt4[0]), int(pt4[1])), (int(end_pt[0]), int(end_pt[1])), clr, thickness)

    # for masks2segments
    def draw_axis(self, img, p, q, color, scale):
        angle = np.arctan2(p[1] - q[1], p[0] - q[0])  # è®¡ç®—è§’åº¦
        hypotenuse = np.sqrt((p[1] - q[1]) ** 2 + (p[0] - q[0]) ** 2)  # è®¡ç®—æ–œè¾¹é•¿åº¦

        # æ”¾å¤§ç®­å¤´é•¿åº¦
        q = (int(p[0] - scale * hypotenuse * np.cos(angle)),
             int(p[1] - scale * hypotenuse * np.sin(angle)))

        # ç”»ä¸»è½´çº¿
        cv2.line(img, p, q, color, 1, cv2.LINE_AA)

        # ç”»ç®­å¤´
        p1 = (int(q[0] + 9 * np.cos(angle + np.pi / 4)),
              int(q[1] + 9 * np.sin(angle + np.pi / 4)))
        cv2.line(img, q, p1, color, 1, cv2.LINE_AA)

        p2 = (int(q[0] + 9 * np.cos(angle - np.pi / 4)),
              int(q[1] + 9 * np.sin(angle - np.pi / 4)))
        cv2.line(img, q, p2, color, 1, cv2.LINE_AA)

    def get_orientation(self, pts, img=None):
        # ç¡®ä¿è½®å»“ç‚¹æ˜¯äºŒç»´æµ®ç‚¹å‹æ•°ç»„
        data_pts = np.array(pts, dtype=np.float64).reshape(-1, 2)

        # è®¡ç®—è½®å»“çš„è´¨å¿ƒ
        mean = np.mean(data_pts, axis=0)
        data_pts -= mean

        # PCA ä¸»æˆåˆ†åˆ†æ
        _, eigenvectors, _ = cv2.PCACompute2(data_pts, mean=None)

        # è·å–è´¨å¿ƒ
        # cntr = (int(mean[0]), int(mean[1]))

        # if img is not None:
        #     # ç»˜åˆ¶è´¨å¿ƒ
        #     cv2.circle(img, cntr, 3, (255, 0, 255), 2)
        #     # ç»˜åˆ¶ä¸»è½´æ–¹å‘
        #     p1 = (int(cntr[0] + 0.02 * eigenvectors[0, 0] * 150),
        #           int(cntr[1] + 0.02 * eigenvectors[0, 1] * 150))
        #     draw_axis(img, cntr, p1, (0, 255, 0), 1)

        return eigenvectors[0]  # è¿”å›ä¸»è½´æ–¹å‘çš„å‘é‡

    def find_adjacent_min_distances(self, contours):
        min_distances = []
        for i in range(len(contours) - 1):
            # è®¡ç®—ç›¸é‚»è½®å»“ä¹‹é—´çš„æœ€çŸ­è·ç¦»
            dists = cdist(contours[i].reshape(-1, 2), contours[i + 1].reshape(-1, 2))
            min_distance = dists.min()  # è·å–æœ€çŸ­è·ç¦»
            min_distances.append(min_distance)

        return min_distances

    def calculate_angle(self, vec1, vec2):
        """è®¡ç®—è½®å»“çš„è§’åº¦å·®å¼‚"""
        dot_product = np.dot(vec1, vec2)
        magnitude1 = np.linalg.norm(vec1)
        magnitude2 = np.linalg.norm(vec2)
        cos_theta = dot_product / (magnitude1 * magnitude2)
        # å¤¹è§’è®¡ç®—ï¼Œå¼§åº¦è½¬ä¸ºè§’åº¦
        angle = np.arccos(cos_theta)
        return np.degrees(angle)

    def alpha_shape(self, points, alpha):
        """
        è®¡ç®—ç‚¹é›†çš„Alpha Shapeï¼ˆå‡¹åŒ…ç»œï¼‰ã€‚
        :param points: ç‚¹çš„é›†åˆ (n, 2)ã€‚
        :param alpha: Alpha å‚æ•°ï¼Œå†³å®šå‡¹åŒ…ç»œçš„ç´§è‡´ç¨‹åº¦ã€‚
        :return: åŒ…ç»œè¾¹ç•Œçš„ç‚¹å¯¹é›†åˆã€‚
        """
        if len(points) < 4:
            # å¦‚æœåªæœ‰ä¸‰ä¸ªç‚¹ï¼Œç›´æ¥è¿”å›å‡¸åŒ…
            return Delaunay(points).convex_hull

        tri = Delaunay(points)
        edges = set()
        for ia, ib, ic in tri.simplices:
            a = np.linalg.norm(points[ia] - points[ib])
            b = np.linalg.norm(points[ib] - points[ic])
            c = np.linalg.norm(points[ic] - points[ia])
            s = (a + b + c) / 2.0
            area = np.sqrt(s * (s - a) * (s - b) * (s - c))
            circum_r = a * b * c / (4.0 * area)
            if circum_r < 1.0 / alpha:
                edges.add(tuple(sorted([ia, ib])))
                edges.add(tuple(sorted([ib, ic])))
                edges.add(tuple(sorted([ic, ia])))
        return np.array(list(edges))

class Build_TRT_model():
    def __init__(self, weight):
        with open(weight, "rb") as f:
            engineString = f.read()
        logger = trt.Logger(trt.Logger.WARNING)
        engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)
        self.tensorname = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]
        self.context = engine.create_execution_context()
        self.nIO = engine.num_io_tensors
        self.nInput = [engine.get_tensor_mode(self.tensorname[i]) for i in range(self.nIO)].count(
            trt.TensorIOMode.INPUT)  # 1ä¸ªè¾“å…¥
        self.dtypes = trt.nptype(engine.get_tensor_dtype(self.tensorname[0]))

    def __call__(self, image):
        # å‡†å¤‡è¾“å…¥æ•°æ®
        bufferH = [image]
        # ä¸ºè¾“å‡ºæ•°æ®åˆ†é…å†…å­˜ 2ä¸ªè¾“å‡º
        for i in range(self.nInput, self.nIO):
            bufferH.append(np.empty(self.context.get_tensor_shape(self.tensorname[i]), self.dtypes))
        # ä¸ºGPUåˆ†é…å†…å­˜
        bufferD = []
        for i in range(self.nIO):
            bufferD.append(cudart.cudaMalloc(bufferH[i].nbytes)[1])
        # å°†æ•°æ®ä»ä¸»æœºç«¯å¤åˆ¶åˆ°è®¾å¤‡ç«¯
        for i in range(self.nInput):
            cudart.cudaMemcpy(bufferD[i], bufferH[i].ctypes.data, bufferH[i].nbytes,
                              cudart.cudaMemcpyKind.cudaMemcpyHostToDevice)
        for i in range(self.nIO):
            self.context.set_tensor_address(self.tensorname[i], int(bufferD[i]))
        self.context.execute_async_v3(0)
        # å°†æ•°æ®ä»è®¾å¤‡ç«¯å¤åˆ¶åˆ°ä¸»æœºç«¯
        for i in range(self.nInput, self.nIO):
            cudart.cudaMemcpy(bufferH[i].ctypes.data, bufferD[i], bufferH[i].nbytes,
                              cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost)
        for buf in bufferD:
            cudart.cudaFree(buf)  # é‡Šæ”¾,ä¸ç„¶è¦ç‚¸
        return bufferH[1:]


class Build_Ort_model():
    def __init__(self, weight):
        self.session = ort.InferenceSession(weight, providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
        if ort.get_device() == 'GPU' else ['CPUExecutionProvider'])
        print(ort.get_device())
        self.dtypes = np.half if self.session.get_inputs()[0].type == 'tensor(float16)' else np.single

    def __call__(self, image):
        res = self.session.run(None, {self.session.get_inputs()[0].name: image})
        return res


class My_LoggerConfig:
    def __init__(self, name='xy', level=logging.INFO):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)
        self._configure_handler()

    def _configure_handler(self):
        # åˆ›å»ºä¸€ä¸ªå¤„ç†å™¨ï¼Œç”¨äºå°†æ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å°
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)

        # åˆ›å»ºä¸€ä¸ªå½©è‰²æ ¼å¼åŒ–å™¨
        formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(levelname)s - %(name)s | - %(message_log_color)s%(message)s",
            datefmt=None,
            reset=True,
            log_colors={
                'DEBUG': 'cyan',
                'INFO': 'green',
                'WARNING': 'yellow',
                'ERROR': 'red',
                'CRITICAL': 'red,bg_white',
            },
            secondary_log_colors={
                'message': {
                    'DEBUG': 'white',
                    'INFO': 'blue',
                    'WARNING': 'purple',
                    'ERROR': 'bg_red',
                    'CRITICAL': 'bg_red',
                }
            }
        )

        # å°†æ ¼å¼åŒ–å™¨æ·»åŠ åˆ°å¤„ç†å™¨
        console_handler.setFormatter(formatter)

        # å°†å¤„ç†å™¨æ·»åŠ åˆ°è®°å½•å™¨
        self.logger.addHandler(console_handler)

    def get_logger(self):
        return self.logger
